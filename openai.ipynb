{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cc6f5ba-e1b9-43ea-a039-80c0055650d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "\n",
    "# OpenAI API Key\n",
    "with open(\"openai-key.txt\", \"r\") as f:\n",
    "    api_key = f.readline()\n",
    "\n",
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42b0f564-d1d5-4060-84fa-fd287fb6992a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'prompt_tokens': 95, 'completion_tokens': 92, 'total_tokens': 187},\n",
       " 'The image shows an illustration of a pair of human legs from the thigh down to the feet. It appears to represent someone walking or in mid-step, with one leg slightly ahead of the other, suggesting motion. The person is not wearing any shoes, and the backdrop is a simple, plain purple color, providing a contrast that highlights the legs. The style of the drawing is not highly detailed but uses clear lines and shapes to represent the form of the legs.')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate(prompt, image_path, verbose = False):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    payload = {\n",
    "      \"model\": \"gpt-4-vision-preview\",\n",
    "      \"messages\": [\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": prompt\n",
    "            },\n",
    "            {\n",
    "              \"type\": \"image_url\",\n",
    "              \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                  \"detail\": \"low\"\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      \"max_tokens\": 128\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload).json()\n",
    "    if verbose:\n",
    "        from PIL import Image\n",
    "        image = Image.open(image_path)\n",
    "        display(image)\n",
    "        print(response)\n",
    "    if \"usage\" not in response and \"error\" in response:\n",
    "        return {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}, response[\"error\"][\"message\"]\n",
    "    return response[\"usage\"], response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "generate(\"Describe this image\", \"images_split/20240101_172315_BUT.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "349ca120-b785-4414-8286-32c06f19cce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 283/283 [00:33<00:00,  8.35it/s, current_usage=1086, total_usage=234076]\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "from tqdm import tqdm\n",
    "\n",
    "## schema [{\"image_path\": <>, \"prompt\": <>, \"usage\": {\"prompt_tokens\": ...}}]\n",
    "with open(\"gpt4-usages.json\", \"r\") as f:\n",
    "    usages = json.load(f)\n",
    "    total_usage = sum(x[\"usage\"][\"total_tokens\"] for x in usages)\n",
    "\n",
    "\n",
    "outpath = \"outputs/right/gpt4-vision-right.json\"\n",
    "try:\n",
    "    with open(outpath, \"r\") as f:\n",
    "        outputs = json.load(f)\n",
    "except Exception:\n",
    "    print(\"starting from zero\")\n",
    "    outputs = []\n",
    "\n",
    "current_usage = 446\n",
    "files = [x for x in os.listdir(\"images_split\") if \"BUT\" in x]\n",
    "pbar = tqdm(files)\n",
    "for filename in pbar:\n",
    "    matching = [o for o in outputs if o[\"image_path\"]==filename and \"Rate limit reached\" not in o[\"output\"]]\n",
    "    if matching:\n",
    "        continue\n",
    "    prompt = \"Describe this image\"\n",
    "    usage, output = generate(prompt, os.path.join(\"images_split\", filename))\n",
    "\n",
    "    outputs.append({\"image_path\":filename, \"output\": output})\n",
    "    with open(outpath, \"w\") as f:\n",
    "        json.dump(outputs, f, indent=2)\n",
    "\n",
    "    usages.append({\"image_path\":filename, \"prompt\": prompt, \"usage\": usage})\n",
    "    with open(\"gpt4-usages.json\", \"w\") as f:\n",
    "        json.dump(usages, f, indent=2)\n",
    "    \n",
    "    current_usage+=usage[\"total_tokens\"]\n",
    "    total_usage+=usage[\"total_tokens\"]\n",
    "    pbar.set_postfix({\"current_usage\": current_usage, \"total_usage\": total_usage})\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888c14f4-0760-4ac2-ab04-9d29af622b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whyfunny: 53930\n",
    "# punchline: 63560\n",
    "# left: \n",
    "# right: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ecd193a-86cb-408e-9f8d-1a7b27b939d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "redo_files = []\n",
    "for o in outputs:\n",
    "    if \"Rate limit reached\" in o[\"output\"]:\n",
    "        redo_files.append(o[\"image_path\"])\n",
    "\n",
    "duplicates = []\n",
    "for i,o in enumerate(outputs):\n",
    "    for j in range(i+1, len(outputs)):\n",
    "        if outputs[j][\"image_path\"] == o[\"image_path\"]:\n",
    "            duplicates.append((o[\"image_path\"],i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2676b637-1896-4d8c-921d-dfc499129027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "24\n",
      "307\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d1ec6a5-90ea-42de-b489-a60ef5f62632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42f29bf8-e7e5-406b-982f-af2c59952e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9cfb00-9fa0-4ee2-bce5-4cbd52c57d64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
