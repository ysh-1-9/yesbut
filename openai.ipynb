{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cc6f5ba-e1b9-43ea-a039-80c0055650d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import requests\n",
    "\n",
    "import subprocess\n",
    "from getpass import getpass\n",
    "\n",
    "password = getpass()\n",
    "cmd = [\"openssl\", \"enc\", \"-d\", \"-aes-256-cbc\", \"-in\", \"openai-key.enc\", \"-pass\", f\"pass:{password}\"]\n",
    "api_key = subprocess.run(cmd, capture_output=True, text=True).stdout.strip(\"\\n\")\n",
    "\n",
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42b0f564-d1d5-4060-84fa-fd287fb6992a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-8qmlRmEtEeTHdHzuEaIirX2aTW5ib', 'object': 'chat.completion', 'created': 1707591197, 'model': 'gpt-4-1106-vision-preview', 'usage': {'prompt_tokens': 273, 'completion_tokens': 114, 'total_tokens': 387}, 'choices': [{'message': {'role': 'assistant', 'content': \"If question mark is replaced by option A, the image will not be funny because the clean and stylish sneakers in the first image don't correlate with the sad expression of smelly socks in option A, which doesn't create a meaningful contrast or satirical context.\\nIf question mark is replaced by option B, the image will be funny because it contrasts the pristine appearance of the sneakers with a mountain of singular lost socks, humorously addressing the common mystery of where the other sock vanishes to in the laundry.\\nHence option B is more funny and the answer is B.\"}, 'finish_reason': 'stop', 'index': 0}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'prompt_tokens': 273, 'completion_tokens': 114, 'total_tokens': 387},\n",
       " \"If question mark is replaced by option A, the image will not be funny because the clean and stylish sneakers in the first image don't correlate with the sad expression of smelly socks in option A, which doesn't create a meaningful contrast or satirical context.\\nIf question mark is replaced by option B, the image will be funny because it contrasts the pristine appearance of the sneakers with a mountain of singular lost socks, humorously addressing the common mystery of where the other sock vanishes to in the laundry.\\nHence option B is more funny and the answer is B.\")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''You are an AI expert in detecting humour or satire. You detect and describe satire in user's image input and then classify it as either funny (Yes) or not funny (No)\n",
    "                        ###Output: exactly \"This image <brief one sentence description of image>. Hence the label is <label>.\", where label is either \"Yes\" or \"No\"'''\n",
    "\n",
    "def generate(prompt, image_path, verbose = False):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    payload = {\n",
    "      \"model\": \"gpt-4-vision-preview\",\n",
    "      \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": \n",
    "                         '''You are an AI expert in creating humour or satire. User gives you an image, and you have to make a choice \"A\" or \"B\".\n",
    "                         ###Input: Given the image in the first row, where one sub-image is given, choose the other sub-image (shown by a question mark) from the two options A/B from the bottom row of images in such a way that the image in the first row is meaningful and satirical.\n",
    "                        ###Output: exactly \"If question mark is replaced by option A, the image <will/will not> be funny because <one sentence>.\n",
    "                        If question mark is replaced by option B, the image <will/will not> be funny because <one sentence>.\n",
    "                        Hence option <answer> is more funny and the answer is <answer>.\" where <answer> must be either \"A\" or \"B\"'''}]\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"image_url\",\n",
    "              \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                  \"detail\": \"low\"\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      \"max_tokens\": 128,\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload).json()\n",
    "    if verbose:\n",
    "        from PIL import Image\n",
    "        image = Image.open(image_path)\n",
    "        display(image)\n",
    "        print(response)\n",
    "    if \"usage\" not in response and \"error\" in response:\n",
    "        raise Exception(response[\"error\"][\"message\"])\n",
    "    return response[\"usage\"], response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "generate(\"\", \"yesbut_image_completion/20240101_173219_LEFT_QMARK.jpg\", True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d190ca04-ff9a-47be-9a6c-59e214dae79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('outputs/dalle3/stick/yes/20240101_172315_STICK_YES.jpg', 'outputs/dalle3/3d/but/20240101_172315_3D_BUT.jpg')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def to_dalle_path(type, og_filename, side):\n",
    "    return os.path.join(f\"outputs/dalle3/{type.lower()}/{side.lower()}\",f\"{og_filename}_{type}_{side}.jpg\")\n",
    "\n",
    "def get_lr_path_from_filename(filename):\n",
    "    if not \"YES\" in filename and not \"BUT\" in filename:\n",
    "        yes = os.path.join(\"images_split\",f\"{filename[:-4]}_YES.jpg\")\n",
    "        but = os.path.join(\"images_split\",f\"{filename[:-4]}_BUT.jpg\")\n",
    "    else:\n",
    "        parts = filename.split(\"_\")\n",
    "        #print(parts)\n",
    "        og_filename = \"_\".join(parts[:-4])\n",
    "        yestype, buttype = parts[-4], parts[-2]\n",
    "        yes = to_dalle_path(yestype, og_filename, \"YES\") if yestype!=\"ORIG\" else os.path.join(\"images_split\",f\"{og_filename}_YES.jpg\")\n",
    "        but = to_dalle_path(buttype, og_filename, \"BUT\") if buttype!=\"ORIG\" else os.path.join(\"images_split\",f\"{og_filename}_BUT.jpg\")\n",
    "    return yes,but\n",
    "\n",
    "print(get_lr_path_from_filename(\"20240101_172315_STICK_YES_3D_BUT.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "349ca120-b785-4414-8286-32c06f19cce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [00:46<00:00,  3.20it/s, current_usage=1830, total_usage=794304, accuracy=0.573]\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "from tqdm import tqdm\n",
    "from validate import validate_file\n",
    "\n",
    "## schema [{\"image_path\": <>, \"prompt\": <>, \"usage\": {\"prompt_tokens\": ...}}]\n",
    "with open(\"gpt4-usages.json\", \"r\") as f:\n",
    "    usages = json.load(f)\n",
    "    total_usage = sum(x[\"usage\"][\"total_tokens\"] for x in usages)\n",
    "\n",
    "outpath = \"outputs/completion/gpt4-vision-cot-full.json\"\n",
    "inpath = \"yesbut_image_completion\"\n",
    "try:\n",
    "    with open(outpath, \"r\") as f:\n",
    "        outputs = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"starting from zero\")\n",
    "    outputs = {}\n",
    "\n",
    "current_usage = 0\n",
    "#files = [x for x in os.listdir(\"images_split\") if \"BUT\" in x]\n",
    "#redo_files = [path for path,output in outputs.items() if \"Rate limit reach\" in output]\n",
    "#print(f\"Redoing {len(redo_files)} files\")\n",
    "files = os.listdir(inpath)\n",
    "redo_files = []\n",
    "# fullfiles = os.listdir(inpath)\n",
    "# files = set()\n",
    "# for filename in fullfiles:\n",
    "#     _,but = get_lr_path_from_filename(filename)\n",
    "#     if \"outputs/dalle3\" in but:\n",
    "#         files.add(but)\n",
    "\n",
    "with open(\"completion_groundtruth.json\", \"r\") as f:\n",
    "    gt = json.load(f)\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "pbar = tqdm(files)\n",
    "for filename in pbar:\n",
    "#for filepath in pbar:\n",
    "#    filename = filepath.split(\"/\")[-1]\n",
    "#    inpath = \"/\".join(filepath.split(\"/\")[:-1])\n",
    "    if filename in outputs and outputs[filename]:\n",
    "        total+=1\n",
    "        correct+= 1 if outputs[filename][-2]==gt[filename] else 0\n",
    "        pbar.set_postfix({\"current_usage\": current_usage, \"total_usage\": total_usage, \"accuracy\": correct/total})\n",
    "        continue\n",
    "    prompt = \"\"\n",
    "    try:\n",
    "        usage, output = generate(prompt, os.path.join(inpath, filename))\n",
    "    except Exception as e:\n",
    "        print(\"Caught exception: \", str(e))\n",
    "        print(\"Could not do: \",filename)\n",
    "        usage = {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}\n",
    "        output = \"\"\n",
    "\n",
    "    outputs[filename] = output\n",
    "    with open(outpath, \"w\") as f:\n",
    "        json.dump(outputs, f, indent=4)\n",
    "\n",
    "    usages.append({\"image_path\":filename, \"prompt\": prompt, \"usage\": usage})\n",
    "    with open(\"gpt4-usages.json\", \"w\") as f:\n",
    "        json.dump(usages, f, indent=2)\n",
    "    \n",
    "    current_usage+=usage[\"total_tokens\"]\n",
    "    total_usage+=usage[\"total_tokens\"]\n",
    "    pbar.set_postfix({\"current_usage\": current_usage, \"total_usage\": total_usage})\n",
    "\n",
    "    total+=1\n",
    "    correct+= 1 if outputs[filename] and outputs[filename][-2]==gt[filename] else 0\n",
    "    pbar.set_postfix({\"current_usage\": current_usage, \"total_usage\": total_usage, \"accuracy\": correct/total})\n",
    "\n",
    "with open(outpath, \"w\") as f:\n",
    "    json.dump(outputs, f, indent=4)\n",
    "# if not validate_file(outpath):\n",
    "#     print(\"Validation failed!\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888c14f4-0760-4ac2-ab04-9d29af622b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whyfunny: 53930\n",
    "# punchline: 63560\n",
    "# left: ~60000\n",
    "# right: ~60000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
