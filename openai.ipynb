{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc6f5ba-e1b9-43ea-a039-80c0055650d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "\n",
    "import subprocess\n",
    "from getpass import getpass\n",
    "\n",
    "password = getpass()\n",
    "cmd = [\"openssl\", \"enc\", \"-d\", \"-aes-256-cbc\", \"-in\", \"openai-key.enc\", \"-pass\", f\"pass:{password}\"]\n",
    "api_key = subprocess.run(cmd, capture_output=True, text=True).stdout.strip(\"\\n\")\n",
    "\n",
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b0f564-d1d5-4060-84fa-fd287fb6992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''You are an AI expert in detecting humour or satire. You detect and describe satire in user's image input and then classify it as either funny (Y) or not funny (N).\n",
    "            ### IMPORTANT: Answer Y ONLY if the image is VERY obviously satirical (or funny).\n",
    "            ###Output format: This image contains <brief description>. Thus, the answer is <exactly only Y or N>.'''\n",
    "\n",
    "def generate(image_path, verbose = False):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    payload = {\n",
    "      \"model\": \"gpt-4-vision-preview\",\n",
    "      \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": prompt}]\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"image_url\",\n",
    "              \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                  \"detail\": \"low\"\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      \"max_tokens\": 256,\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload).json()\n",
    "    if verbose:\n",
    "        from PIL import Image\n",
    "        image = Image.open(image_path)\n",
    "        display(image)\n",
    "        print(response)\n",
    "    if \"usage\" not in response and \"error\" in response:\n",
    "        raise Exception(response[\"error\"][\"message\"])\n",
    "    return response[\"usage\"], response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "generate(\"images/20240101_173254.jpg\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349ca120-b785-4414-8286-32c06f19cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "## schema [{\"image_path\": <>, \"prompt\": <>, \"usage\": {\"prompt_tokens\": ...}}]\n",
    "with open(\"gpt4-usages.json\", \"r\") as f:\n",
    "    usages = json.load(f)\n",
    "    total_usage = sum(x[\"usage\"][\"total_tokens\"] for x in usages)\n",
    "\n",
    "outpath = \"outputs/detection/gpt4-vision-cot.json\"\n",
    "inpaths = [\"images\",\"yesbut_second_round\",\"yesbut_second_round_negatives\", \"yesbut_third_round\", \"yesbut_third_round_negatives\"]\n",
    "\n",
    "try:\n",
    "    with open(outpath, \"r\") as f:\n",
    "        outputs = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"starting from zero\")\n",
    "    outputs = {}\n",
    "\n",
    "def get_pred(output):\n",
    "    if not output:\n",
    "        return \"\"\n",
    "    return output[-2]\n",
    "\n",
    "def is_correct(pred, folder):\n",
    "    if not pred:\n",
    "        return False\n",
    "    return (pred==\"Y\" and \"negative\" not in folder) or (pred==\"N\" and \"negative\" in folder)\n",
    "\n",
    "current_usage = 0\n",
    "total, correct, adhering, y = 0,0,0,0\n",
    "files = sum(([os.path.join(folder, file) for file in os.listdir(folder) if file[-3:]==\"jpg\"] for folder in inpaths),[])   \n",
    "random.Random(42).shuffle(files)\n",
    "pbar = tqdm(files)\n",
    "for filepath in pbar:\n",
    "    folder,file = filepath.split('/')\n",
    "    if filepath in outputs and outputs[filepath]:\n",
    "        total+=1\n",
    "        pred = get_pred(outputs[filepath])\n",
    "        correct += 1 if is_correct(pred,folder) else 0\n",
    "        adhering += 1 if pred in [\"Y\", \"N\"] else 0\n",
    "        y += 1 if pred==\"Y\" else 0\n",
    "        pbar.set_postfix({\"current_usage\": current_usage, \"total_usage\": total_usage, \"folder\": folder, \"total\": total, \"accuracy\": correct/total, \"adherance\": adhering/total, \"y%\": y/adhering if adhering>0 else 0})\n",
    "        continue\n",
    "    try:\n",
    "        usage, output = generate(filepath)\n",
    "    except Exception as e:\n",
    "        print(\"Caught exception: \", str(e))\n",
    "        print(\"Could not do: \",filepath)\n",
    "        usage = {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}\n",
    "        output = \"\"\n",
    "\n",
    "    outputs[filepath] = output\n",
    "    with open(outpath, \"w\") as f:\n",
    "        json.dump(outputs, f, indent=4)\n",
    "\n",
    "    usages.append({\"image_path\":filepath, \"prompt\": prompt, \"usage\": usage})\n",
    "    with open(\"gpt4-usages.json\", \"w\") as f:\n",
    "        json.dump(usages, f, indent=2)\n",
    "    \n",
    "    current_usage+=usage[\"total_tokens\"]\n",
    "    total_usage+=usage[\"total_tokens\"]\n",
    "\n",
    "    total+=1\n",
    "    pred = get_pred(outputs[filepath])\n",
    "    correct += 1 if is_correct(pred,folder) else 0\n",
    "    adhering += 1 if pred in [\"Y\", \"N\"] else 0\n",
    "    y += 1 if pred==\"Y\" else 0\n",
    "    pbar.set_postfix({\"current_usage\": current_usage, \"total_usage\": total_usage, \"folder\": folder, \"total\": total, \"accuracy\": correct/total, \"adherance\": adhering/total, \"y%\": y/adhering if adhering>0 else 0})\n",
    "\n",
    "with open(outpath, \"w\") as f:\n",
    "    json.dump(outputs, f, indent=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888c14f4-0760-4ac2-ab04-9d29af622b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whyfunny: 53930\n",
    "# punchline: 63560\n",
    "# left: ~60000\n",
    "# right: ~60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f3efd9-a740-4325-9ef5-7cab51d5899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "positives - 1084:\n",
    "    1. original - 283\n",
    "    2. second_round - 302\n",
    "    3. third_round - 499\n",
    "negatives - 1463:\n",
    "    1. second_round - 547\n",
    "    2. third_round - 916"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
