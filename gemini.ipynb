{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf7d0370-b93e-4f86-ac14-8b7879c59688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This image is funny because it is a visual pun on the phrase \"pumpkin spice.\" The first half of the image shows a woman planting pumpkin seeds, and the second half shows a pumpkin spice latte. The humor lies in the juxtaposition of these two images, as the woman is literally planting pumpkin spice. Thus, my answer is Y.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "from PIL import Image\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, Part\n",
    "from vertexai.generative_models._generative_models import HarmCategory, HarmBlockThreshold, ResponseBlockedError\n",
    "from pathlib import Path\n",
    "\n",
    "vertexai.init(project=\"crypto-resolver-346012\", location=\"us-central1\")\n",
    "\n",
    "prompt = '''You are an AI expert in detecting humour or satire. User gives you an image, and you have to make a choice \"Y\" or \"N\".\n",
    "###Instructions: Users image has 2 halves called yes and but, and the combination of those might make no sense at all, or be funny. Even though yesbut is a meme format, users image is edited and might not be a meme. Your job is to find out which one it is and output Y ONLY if its funny and N otherwise.\n",
    "###Output format: This image is <funny/not funny> because <reason>. Thus, my answer is <Y/N>'''\n",
    "def generate(image):\n",
    "    model = GenerativeModel(\"gemini-pro-vision\")\n",
    "    \n",
    "    safety_settings = {\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    }\n",
    "\n",
    "    # Yes,But memes are funny because the Yes picture depicts a normal situation, and the But picture reveals something about the Yes picture that makes humans laugh. What is funny about the given Yes,But meme\n",
    "    \n",
    "    responses = model.generate_content(\n",
    "        [prompt,image],\n",
    "        generation_config={\n",
    "            \"max_output_tokens\": 256,\n",
    "            \"temperature\": 1,\n",
    "            \"top_p\": 1,\n",
    "            \"top_k\": 32,\n",
    "            \"candidate_count\": 1\n",
    "        },\n",
    "        safety_settings=safety_settings,\n",
    "        \n",
    "    )\n",
    "    #print(type(responses))\n",
    "    #print(responses)\n",
    "    #print(responses.text)\n",
    "    return responses.text\n",
    "\n",
    "\n",
    "with open(\"yesbut_third_round_negatives/20240101_172858_3D_YES_STICK_BUT.jpg\", \"rb\") as f:\n",
    "    data = f.read()\n",
    "    image1 = Part.from_data(data=data, mime_type=\"image/jpeg\")\n",
    "    #print(image1)\n",
    "\n",
    "generate(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6021e12a-bd91-4ce8-a497-7b0456e857ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "You are an AI expert in creating humour or satire. User gives you an image, and you have to make a choice \"A\" or \"B\".\n",
    "\n",
    "###Structure of image: The image is a 2x2 table with the labels \"yes\", \"but\", \"A\", and \"B\". Either the \"yes\" cell or the \"but\" cell will have a question mark in it. Your job is to replace the question mark with either cell \"A\" or cell \"B\" so that the resulting <yes,but> pair is funny or satirical.\n",
    "\n",
    "###Output format: Option <answer> is more funny because <reason>\" where <answer> must be either \"A\" or \"B\"\n",
    "\n",
    "'''\n",
    "\n",
    "###Output format: \" Thus, option <answer> is more funny because <reason>\" where <answer> must be either \"A\" or \"B\"\n",
    "\n",
    "\"When the question mark is replaced by image A, the resulting [yes,but] pair is <describe it here>.\n",
    "When the question mark is replaced by image B, the resulting [yes,but] pair is <describe it here>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c60a0c5f-2fc5-4ed5-b8c1-d1ebba7743c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|‚ñè                                                        | 9/2547 [00:46<3:37:41,  5.15s/it, folder=yesbut_third_round_negatives, total=9, accuracy=0.444, adherance=1, y%=1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#display(Image.open(os.path.join(\"images\",filename)).convert('RGB'))\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#print(filename)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCaught exception: \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28mstr\u001b[39m(e))\n",
      "Cell \u001b[0;32mIn[31], line 25\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     16\u001b[0m safety_settings \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     17\u001b[0m     HarmCategory\u001b[38;5;241m.\u001b[39mHARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold\u001b[38;5;241m.\u001b[39mBLOCK_ONLY_HIGH,\n\u001b[1;32m     18\u001b[0m     HarmCategory\u001b[38;5;241m.\u001b[39mHARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold\u001b[38;5;241m.\u001b[39mBLOCK_ONLY_HIGH,\n\u001b[1;32m     19\u001b[0m     HarmCategory\u001b[38;5;241m.\u001b[39mHARM_CATEGORY_HARASSMENT: HarmBlockThreshold\u001b[38;5;241m.\u001b[39mBLOCK_ONLY_HIGH,\n\u001b[1;32m     20\u001b[0m     HarmCategory\u001b[38;5;241m.\u001b[39mHARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold\u001b[38;5;241m.\u001b[39mBLOCK_ONLY_HIGH,\n\u001b[1;32m     21\u001b[0m }\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Yes,But memes are funny because the Yes picture depicts a normal situation, and the But picture reveals something about the Yes picture that makes humans laugh. What is funny about the given Yes,But meme\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m responses \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_output_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcandidate_count\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#print(type(responses))\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#print(responses)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#print(responses.text)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m responses\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[0;32m~/recipe_llava/.env/lib/python3.9/site-packages/vertexai/generative_models/_generative_models.py:353\u001b[0m, in \u001b[0;36m_GenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, stream)\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content_streaming(\n\u001b[1;32m    347\u001b[0m         contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    348\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[1;32m    349\u001b[0m         safety_settings\u001b[38;5;241m=\u001b[39msafety_settings,\n\u001b[1;32m    350\u001b[0m         tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[1;32m    351\u001b[0m     )\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/recipe_llava/.env/lib/python3.9/site-packages/vertexai/generative_models/_generative_models.py:437\u001b[0m, in \u001b[0;36m_GenerativeModel._generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# generate_content is not available\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# gapic_response = self._prediction_client.generate_content(request=request)\u001b[39;00m\n\u001b[1;32m    436\u001b[0m gapic_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 437\u001b[0m stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prediction_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_generate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gapic_chunk \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gapic_response:\n",
      "File \u001b[0;32m~/recipe_llava/.env/lib/python3.9/site-packages/google/cloud/aiplatform_v1beta1/services/prediction_service/client.py:1634\u001b[0m, in \u001b[0;36mPredictionServiceClient.stream_generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1629\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(metadata) \u001b[38;5;241m+\u001b[39m (\n\u001b[1;32m   1630\u001b[0m     gapic_v1\u001b[38;5;241m.\u001b[39mrouting_header\u001b[38;5;241m.\u001b[39mto_grpc_metadata(((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmodel),)),\n\u001b[1;32m   1631\u001b[0m )\n\u001b[1;32m   1633\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 1634\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1639\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1641\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/recipe_llava/.env/lib/python3.9/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/recipe_llava/.env/lib/python3.9/site-packages/google/api_core/grpc_helpers.py:173\u001b[0m, in \u001b[0;36m_wrap_stream_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# Auto-fetching the first result causes PubSub client's streaming pull\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# to hang when re-opening the stream, thus we need examine the hacky\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;66;03m# hidden flag to see if pre-fetching is disabled.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m# https://github.com/googleapis/python-pubsub/issues/93#issuecomment-630762257\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     prefetch_first \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callable_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_prefetch_first_result_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_StreamingResponseIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefetch_first_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefetch_first\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m~/recipe_llava/.env/lib/python3.9/site-packages/google/api_core/grpc_helpers.py:95\u001b[0m, in \u001b[0;36m_StreamingResponseIterator.__init__\u001b[0;34m(self, wrapped, prefetch_first_result)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prefetch_first_result:\n\u001b[0;32m---> 95\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stored_first_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# It is possible the wrapped method isn't an iterable (a grpc.Call\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# for instance). If this happens don't store the first result.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/recipe_llava/.env/lib/python3.9/site-packages/grpc/_channel.py:540\u001b[0m, in \u001b[0;36m_Rendezvous.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/recipe_llava/.env/lib/python3.9/site-packages/grpc/_channel.py:957\u001b[0m, in \u001b[0;36m_MultiThreadedRendezvous._next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_response_ready\u001b[39m():\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mresponse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    953\u001b[0m         cygrpc\u001b[38;5;241m.\u001b[39mOperationType\u001b[38;5;241m.\u001b[39mreceive_message \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mdue\n\u001b[1;32m    954\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    955\u001b[0m     )\n\u001b[0;32m--> 957\u001b[0m \u001b[43m_common\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_response_ready\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mresponse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    959\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mresponse\n",
      "File \u001b[0;32m~/recipe_llava/.env/lib/python3.9/site-packages/grpc/_common.py:156\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(wait_fn, wait_complete_fn, timeout, spin_cb)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m wait_complete_fn():\n\u001b[0;32m--> 156\u001b[0m         \u001b[43m_wait_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAXIMUM_WAIT_TIMEOUT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspin_cb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m timeout\n",
      "File \u001b[0;32m~/recipe_llava/.env/lib/python3.9/site-packages/grpc/_common.py:116\u001b[0m, in \u001b[0;36m_wait_once\u001b[0;34m(wait_fn, timeout, spin_cb)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wait_once\u001b[39m(\n\u001b[1;32m    112\u001b[0m     wait_fn: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mbool\u001b[39m],\n\u001b[1;32m    113\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[1;32m    114\u001b[0m     spin_cb: Optional[Callable[[], \u001b[38;5;28;01mNone\u001b[39;00m]],\n\u001b[1;32m    115\u001b[0m ):\n\u001b[0;32m--> 116\u001b[0m     \u001b[43mwait_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spin_cb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m         spin_cb()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os,json\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "outpath = \"outputs/detection/gemini-cot.json\"\n",
    "inpaths = [\"images\",\"yesbut_second_round\",\"yesbut_second_round_negatives\", \"yesbut_third_round\", \"yesbut_third_round_negatives\"]\n",
    "\n",
    "try:\n",
    "    with open(outpath, \"r\") as f:\n",
    "        outputs = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"starting from zero\")\n",
    "    outputs = {}\n",
    "\n",
    "def get_pred(output):\n",
    "    if not output:\n",
    "        return \"\"\n",
    "    return output.strip(' .')[-1]\n",
    "\n",
    "def is_correct(pred, folder):\n",
    "    if not pred:\n",
    "        return False\n",
    "    return (pred==\"Y\" and \"negative\" not in folder) or (pred==\"N\" and \"negative\" in folder)\n",
    "\n",
    "total, correct, adhering, y = 0,0,0,0\n",
    "files = sum(([os.path.join(folder, file) for file in os.listdir(folder) if file[-3:]==\"jpg\"] for folder in inpaths),[])   \n",
    "random.Random(42).shuffle(files)\n",
    "pbar = tqdm(files)\n",
    "for filepath in pbar:\n",
    "    folder,file = filepath.split('/')\n",
    "    if filepath in outputs and outputs[filepath]:\n",
    "        total+=1\n",
    "        pred = get_pred(outputs[filepath])\n",
    "        correct += 1 if is_correct(pred,folder) else 0\n",
    "        adhering += 1 if pred in [\"Y\", \"N\"] else 0\n",
    "        y += 1 if pred==\"Y\" else 0\n",
    "        pbar.set_postfix({\"folder\": folder, \"total\": total, \"accuracy\": correct/total, \"adherance\": adhering/total, \"y%\": y/adhering if adhering>0 else 0})\n",
    "        continue\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        data = f.read()\n",
    "        image = Part.from_data(data=data, mime_type=\"image/jpeg\")\n",
    "    #display(Image.open(os.path.join(\"images\",filename)).convert('RGB'))\n",
    "    #print(filename)\n",
    "    try:\n",
    "        output = generate(image)\n",
    "    except Exception as e:\n",
    "        print(\"Caught exception: \",str(e))\n",
    "        print(\"Could not do file: \",filepath)\n",
    "        output = \"\"\n",
    "    \n",
    "    outputs[filepath]= output\n",
    "    with open(outpath, \"w\") as f:\n",
    "        json.dump(outputs, f, indent=4)\n",
    "        \n",
    "    total+=1\n",
    "    pred = get_pred(output)\n",
    "    correct += 1 if is_correct(pred,folder) else 0\n",
    "    adhering += 1 if pred in [\"Y\", \"N\"] else 0\n",
    "    y += 1 if pred==\"Y\" else 0\n",
    "    pbar.set_postfix({\"folder\": folder, \"total\": total, \"accuracy\": correct/total, \"adherance\": adhering/total, \"y%\": y/adhering if adhering>0 else 0})\n",
    "\n",
    "with open(outpath, \"w\") as f:\n",
    "    json.dump(outputs, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea2648c-ba06-4dca-8fe1-7846628db461",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Caught exception:  500 Internal error encountered.\n",
    "Could not do file:  20240101_172932.jpg\n",
    "\n",
    "Caught exception:  500 Internal error encountered.\n",
    "Could not do file:  20240101_182249.jpg\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5dbbaf-0d97-408c-872c-67ae9c7b241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "manually redid:\n",
    "[\"20240101_173205_BUT.jpg\", \"20240101_173205_YES.jpg\", \"20240101_174949_BUT.jpg\", \"20240101_174949_YES.jpg\", \"20240101_181310_YES.jpg\"]\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
