{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf7d0370-b93e-4f86-ac14-8b7879c59688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The image is trying to highlight how people often search for things, but aren\\'t usually typing in the search bar. The contrast with \"YES\" followed by things people do type in the search bar versus \"BUT\" followed by things that are typed with voice search is funny because it\\'s unexpected.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "from PIL import Image\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, Part\n",
    "from vertexai.generative_models._generative_models import HarmCategory, HarmBlockThreshold, ResponseBlockedError\n",
    "from pathlib import Path\n",
    "\n",
    "gcp_project_name = \"crypto-resolver-346012\" # get this from your google cloud platform account\n",
    "vertexai.init(project=gcp_project_name, location=\"us-central1\")\n",
    "\n",
    "prompt = '''You are an AI expert in detecting humour or satire. User gives you an image, and you have to make a choice \"Y\" or \"N\".\n",
    "###Instructions: Users image has 2 halves called yes and but, and the combination of those might make no sense at all, or be funny. Even though yesbut is a meme format, users image is edited and might not be a meme. Your job is to find out which one it is and output Y ONLY if its funny and N otherwise.\n",
    "###Output format: This image is <funny/not funny> because <reason>. Thus, my answer is <Y/N>'''\n",
    "prompt = \"Why is this image funny/satirical? Explain in about 50-70 words\"\n",
    "def generate(image):\n",
    "    model = GenerativeModel(\"gemini-pro-vision\")\n",
    "    \n",
    "    safety_settings = {\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    }\n",
    "\n",
    "    # Yes,But memes are funny because the Yes picture depicts a normal situation, and the But picture reveals something about the Yes picture that makes humans laugh. What is funny about the given Yes,But meme\n",
    "    \n",
    "    responses = model.generate_content(\n",
    "        [prompt,image],\n",
    "        generation_config={\n",
    "            \"max_output_tokens\": 256,\n",
    "            \"temperature\": 1,\n",
    "            \"top_p\": 1,\n",
    "            \"top_k\": 32,\n",
    "            \"candidate_count\": 1\n",
    "        },\n",
    "        safety_settings=safety_settings,\n",
    "        \n",
    "    )\n",
    "    #print(type(responses))\n",
    "    #print(responses)\n",
    "    #print(responses.text)\n",
    "    return responses.text\n",
    "\n",
    "\n",
    "with open(\"images_real/Screenshot_2024-05-23-20-22-16-966_com.instagram.android.jpg\", \"rb\") as f:\n",
    "    data = f.read()\n",
    "    image1 = Part.from_data(data=data, mime_type=\"image/jpeg\")\n",
    "    #print(image1)\n",
    "\n",
    "generate(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6021e12a-bd91-4ce8-a497-7b0456e857ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "You are an AI expert in creating humour or satire. User gives you an image, and you have to make a choice \"A\" or \"B\".\n",
    "\n",
    "###Structure of image: The image is a 2x2 table with the labels \"yes\", \"but\", \"A\", and \"B\". Either the \"yes\" cell or the \"but\" cell will have a question mark in it. Your job is to replace the question mark with either cell \"A\" or cell \"B\" so that the resulting <yes,but> pair is funny or satirical.\n",
    "\n",
    "###Output format: Option <answer> is more funny because <reason>\" where <answer> must be either \"A\" or \"B\"\n",
    "\n",
    "'''\n",
    "\n",
    "###Output format: \" Thus, option <answer> is more funny because <reason>\" where <answer> must be either \"A\" or \"B\"\n",
    "\n",
    "\"When the question mark is replaced by image A, the resulting [yes,but] pair is <describe it here>.\n",
    "When the question mark is replaced by image B, the resulting [yes,but] pair is <describe it here>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c60a0c5f-2fc5-4ed5-b8c1-d1ebba7743c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|██████████████████████████▊    | 103/119 [01:10<00:45,  2.86s/it, folder=images_real, total=103, accuracy=0.689, adherance=0.854, y%=0.807]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught exception:  429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-pro-vision. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.\n",
      "sleeping for ~60+5s\n",
      "sleep over\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████▌  | 110/119 [03:02<01:13,  8.17s/it, folder=images_real, total=110, accuracy=0.691, adherance=0.864, y%=0.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught exception:  429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-pro-vision. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.\n",
      "sleeping for ~13+5s\n",
      "sleep over\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|████████████████████████████▉  | 111/119 [03:28<01:45, 13.21s/it, folder=images_real, total=111, accuracy=0.694, adherance=0.865, y%=0.802]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught exception:  429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-pro-vision. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.\n",
      "sleeping for ~51+5s\n",
      "sleep over\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|██████████████████████████████▍| 117/119 [05:04<00:19,  9.94s/it, folder=images_real, total=117, accuracy=0.692, adherance=0.872, y%=0.794]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught exception:  429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-pro-vision. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.\n",
      "sleeping for ~20+5s\n",
      "sleep over\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 119/119 [05:44<00:00,  2.90s/it, folder=images_real, total=119, accuracy=0.697, adherance=0.874, y%=0.798]\n"
     ]
    }
   ],
   "source": [
    "import os,json\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "outpath = \"outputs/detection/gemini-cot-real.json\"\n",
    "inpaths = [\"images_real\"]\n",
    "\n",
    "try:\n",
    "    with open(outpath, \"r\") as f:\n",
    "        outputs = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"starting from zero\")\n",
    "    outputs = {}\n",
    "\n",
    "def get_pred(output):\n",
    "    if not output:\n",
    "        return \"\"\n",
    "    return output.strip(' .')[-1]\n",
    "\n",
    "def is_correct(pred, folder):\n",
    "    if not pred:\n",
    "        return False\n",
    "    return (pred==\"Y\" and \"negative\" not in folder) or (pred==\"N\" and \"negative\" in folder)\n",
    "\n",
    "total, correct, adhering, y = 0,0,0,0\n",
    "files = sum(([os.path.join(folder, file) for file in os.listdir(folder) if file[-3:]==\"jpg\"] for folder in inpaths),[])   \n",
    "random.Random(42).shuffle(files)\n",
    "pbar = tqdm(files)\n",
    "t_last = None\n",
    "for filepath in pbar:\n",
    "    folder,file = filepath.split('/')\n",
    "    if filepath in outputs and outputs[filepath]:\n",
    "        total+=1\n",
    "        pred = get_pred(outputs[filepath])\n",
    "        correct += 1 if is_correct(pred,folder) else 0\n",
    "        adhering += 1 if pred in [\"Y\", \"N\"] else 0\n",
    "        y += 1 if pred==\"Y\" else 0\n",
    "        pbar.set_postfix({\"folder\": folder, \"total\": total, \"accuracy\": correct/total, \"adherance\": adhering/total, \"y%\": y/adhering if adhering>0 else 0})\n",
    "        continue\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        data = f.read()\n",
    "        image = Part.from_data(data=data, mime_type=\"image/jpeg\")\n",
    "    #display(Image.open(os.path.join(\"images\",filename)).convert('RGB'))\n",
    "    #print(filename)\n",
    "    try:\n",
    "        output = generate(image)\n",
    "    except Exception as e:\n",
    "        print(\"Caught exception: \",str(e))\n",
    "        if \"generate_content_requests_per_minute_per_project_per_base_model\" in str(e):\n",
    "            timediff = int(60-(datetime.now()-t_last).total_seconds() if t_last else 60)\n",
    "            print(f\"sleeping for ~{timediff}+5s\")\n",
    "            time.sleep(timediff+5)\n",
    "            print(\"sleep over\")\n",
    "            t_last = datetime.now()\n",
    "            output = generate(image)\n",
    "        else:\n",
    "            print(\"Could not do file: \",filepath)\n",
    "            output = \"\"\n",
    "    \n",
    "    outputs[filepath]= output\n",
    "    with open(outpath, \"w\") as f:\n",
    "        json.dump(outputs, f, indent=4)\n",
    "        \n",
    "    total+=1\n",
    "    pred = get_pred(output)\n",
    "    correct += 1 if is_correct(pred,folder) else 0\n",
    "    adhering += 1 if pred in [\"Y\", \"N\"] else 0\n",
    "    y += 1 if pred==\"Y\" else 0\n",
    "    pbar.set_postfix({\"folder\": folder, \"total\": total, \"accuracy\": correct/total, \"adherance\": adhering/total, \"y%\": y/adhering if adhering>0 else 0})\n",
    "\n",
    "with open(outpath, \"w\") as f:\n",
    "    json.dump(outputs, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2947962f-def0-471c-bdb5-c5bf84d39de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████▍   | 109/119 [00:54<00:17,  1.73s/it, folder=images_real, total=109, accuracy=0, adherance=0, y%=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught exception:  429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-pro-vision. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.\n",
      "sleeping for ~120+5s\n",
      "sleep over\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 119/119 [04:03<00:00,  2.05s/it, folder=images_real, total=119, accuracy=0, adherance=0, y%=0]\n"
     ]
    }
   ],
   "source": [
    "import os,json\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "outpath = \"outputs/annotations/images_real/whyfunny/gemini-whyfunny.json\"\n",
    "inpaths = [\"images_real\"]\n",
    "\n",
    "try:\n",
    "    with open(outpath, \"r\") as f:\n",
    "        outputs = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"starting from zero\")\n",
    "    outputs = {}\n",
    "\n",
    "def get_pred(output):\n",
    "    if not output:\n",
    "        return \"\"\n",
    "    return output.strip(' .')[-1]\n",
    "\n",
    "def is_correct(pred, folder):\n",
    "    if not pred:\n",
    "        return False\n",
    "    return (pred==\"Y\" and \"negative\" not in folder) or (pred==\"N\" and \"negative\" in folder)\n",
    "\n",
    "total, correct, adhering, y = 0,0,0,0\n",
    "files = sum(([os.path.join(folder, file) for file in os.listdir(folder) if file[-3:]==\"jpg\"] for folder in inpaths),[])   \n",
    "random.Random(42).shuffle(files)\n",
    "pbar = tqdm(files)\n",
    "t_last = None\n",
    "for filepath in pbar:\n",
    "    folder,file = filepath.split('/')\n",
    "    if filepath in outputs and outputs[filepath]:\n",
    "        total+=1\n",
    "        pred = get_pred(outputs[filepath])\n",
    "        correct += 1 if is_correct(pred,folder) else 0\n",
    "        adhering += 1 if pred in [\"Y\", \"N\"] else 0\n",
    "        y += 1 if pred==\"Y\" else 0\n",
    "        pbar.set_postfix({\"folder\": folder, \"total\": total, \"accuracy\": correct/total, \"adherance\": adhering/total, \"y%\": y/adhering if adhering>0 else 0})\n",
    "        continue\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        data = f.read()\n",
    "        image = Part.from_data(data=data, mime_type=\"image/jpeg\")\n",
    "    #display(Image.open(os.path.join(\"images\",filename)).convert('RGB'))\n",
    "    #print(filename)\n",
    "    try:\n",
    "        output = generate(image)\n",
    "    except Exception as e:\n",
    "        print(\"Caught exception: \",str(e))\n",
    "        if \"generate_content_requests_per_minute_per_project_per_base_model\" in str(e):\n",
    "            timediff = int(120-(datetime.now()-t_last).total_seconds() if t_last else 120)\n",
    "            print(f\"sleeping for ~{timediff}+5s\")\n",
    "            time.sleep(timediff+5)\n",
    "            print(\"sleep over\")\n",
    "            t_last = datetime.now()\n",
    "            output = generate(image)\n",
    "        else:\n",
    "            print(\"Could not do file: \",filepath)\n",
    "            output = \"\"\n",
    "    \n",
    "    outputs[filepath]= output\n",
    "    with open(outpath, \"w\") as f:\n",
    "        json.dump(outputs, f, indent=4)\n",
    "        \n",
    "    total+=1\n",
    "    pred = get_pred(output)\n",
    "    correct += 1 if is_correct(pred,folder) else 0\n",
    "    adhering += 1 if pred in [\"Y\", \"N\"] else 0\n",
    "    y += 1 if pred==\"Y\" else 0\n",
    "    pbar.set_postfix({\"folder\": folder, \"total\": total, \"accuracy\": correct/total, \"adherance\": adhering/total, \"y%\": y/adhering if adhering>0 else 0})\n",
    "\n",
    "with open(outpath, \"w\") as f:\n",
    "    json.dump(outputs, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea2648c-ba06-4dca-8fe1-7846628db461",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Caught exception:  500 Internal error encountered.\n",
    "Could not do file:  20240101_172932.jpg\n",
    "\n",
    "Caught exception:  500 Internal error encountered.\n",
    "Could not do file:  20240101_182249.jpg\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5dbbaf-0d97-408c-872c-67ae9c7b241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "manually redid:\n",
    "[\"20240101_173205_BUT.jpg\", \"20240101_173205_YES.jpg\", \"20240101_174949_BUT.jpg\", \"20240101_174949_YES.jpg\", \"20240101_181310_YES.jpg\"]\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
